\newpage
\chapter{TINJAUAN PUSTAKA} \label{Bab II}

\section{Tinjauan Pustaka} \label{II.Tinjauan}
Bab ini merangkum literatur utama terkait QA dokumen PDF berbahasa Indonesia, dengan
fokus pada (i) arsitektur \textit{transformer}, (ii) \textit{retrieval-augmented} QA, dan
(iii) ekosistem model/data Indonesia. Lima karya paling relevan dipilih karena langsung
menyangga rancangan pipeline PDF \textrightarrow{} segmentasi \textrightarrow{}
retrieval \textrightarrow{} reader IndoBERT-Lite:
\begin{enumerate}[noitemsep]
    \item Saad-Falcon et al. (PDFTriage) \cite{saad2023pdftriage}: QA dokumen panjang
    berstruktur (PDF), menekankan segmentasi blok/layout sebelum retrieval.
    \item Lovenia et al. (SEACrowd) \cite{lovenia2024seacrowd}: ekosistem data/benchmark
    Asia Tenggara; relevan untuk legitimasi evaluasi bahasa Indonesia.
    \item Wilie et al. (IndoNLU/IndoBERT) \cite{wilie2020indonlu}: model/dataset kunci
    untuk NLU Indonesia; landasan pemilihan IndoBERT/IndoBERT-Lite.
    \item Karpukhin et al. (DPR) \cite{karpukhin2020dpr}: baseline \textit{dense}
    retrieval untuk memilih paragraf relevan sebelum modul QA.
    \item Jurafsky \& Martin (SLP 3rd draft) \cite{jurafsky2025slp}: kerangka teori NLP,
    IR, dan evaluasi yang netral akademik.
\end{enumerate}
Karya fondasional \cite{vaswani2017attention,devlin2019bert,wilie2020indobert,lewis2020rag}
digunakan sebagai rujukan arsitektur/pipeline pendukung.

\section{Dasar Teori} \label{II.Teori}
Transformer dan self-attention. Vaswani et al. \cite{vaswani2017attention}
memperkenalkan \textit{multi-head self-attention} yang menggantikan rekuren, memungkinkan
pemodelan dependensi jarak jauh secara paralel. Devlin et al.
\cite{devlin2019bert,wilie2020indobert} menerapkannya pada BERT/IndoBERT untuk tugas
ekstraktif.

Retrieval-augmented QA. Lewis et al. \cite{lewis2020rag} memisahkan tahap
\textit{retriever} (dense) dan reader/generator, sehingga konteks panjang tidak perlu
dimuat sekaligus. DPR \cite{karpukhin2020dpr} menjadi baseline \textit{dense retriever}
untuk memilih paragraf relevan.

Dokumen panjang/berlayout. PDFTriage \cite{saad2023pdftriage} menegaskan bahwa
segmentasi blok teks/layout pada PDF sebelum retrieval meningkatkan presisi dan
keterlacakan paragraf sumber.

Ekosistem Indonesia. IndoNLU/IndoBERT \cite{wilie2020indonlu,wilie2020indobert}
menyediakan backbone dan tolok ukur; SEACrowd \cite{lovenia2024seacrowd} memperkuat
relevansi evaluasi lintas bahasa Asia Tenggara. SLP \cite{jurafsky2025slp} memberi
kerangka konseptual NLP/IR dan metrik (EM/F1).

\section{Sintesis Literatur Primer}
\begin{enumerate}[noitemsep]
    \item \textbf{PDFTriage} \cite{saad2023pdftriage}: menunjukkan pentingnya segmentasi
    layout-aware untuk QA PDF; relevan untuk SOP/pedoman multi-bab.
    \item \textbf{SEACrowd} \cite{lovenia2024seacrowd}: menyoroti ketersediaan data dan
    pentingnya evaluasi bahasa Indonesia dalam lanskap Asia Tenggara.
    \item \textbf{IndoNLU/IndoBERT(-Lite)} \cite{wilie2020indonlu,wilie2020indobert}:
    menyediakan model dasar efisien untuk \textit{fine-tuning} QA Indonesia.
    \item \textbf{DPR} \cite{karpukhin2020dpr}: \textit{dense retriever} untuk memilih
    paragraf; cocok digabung dengan reader IndoBERT-Lite.
    \item \textbf{SLP} \cite{jurafsky2025slp}: kerangka teori NLP/IR untuk merapikan
    definisi dan metrik evaluasi.
\end{enumerate}

\section{State-of-the-Art dan Celah Riset}
Praktik mutakhir. Pipeline QA modern memadukan retriever padat (DPR/ColBERT) dan
reader transformer; RAG \cite{lewis2020rag} mengurangi beban konteks panjang dengan
retrieval terpisah; PDFTriage menambah perspektif layout-aware.

Terdapat beberapa \textit{research gap} yang bisa diidentifikasi:
\begin{enumerate}[noitemsep]
    \item Belum ada evaluasi terukur IndoBERT-Lite untuk QA PDF institusional berbahasa
    Indonesia dengan struktur bab/subbab.
    \item Belum ada perbandingan sistematis segmentasi PDF (blok/halaman vs paragraf
    logis) terhadap kualitas retrieval dan jawaban.
    \item Pelacakan sumber (paragraf/halaman) pada jawaban QA PDF Indonesia belum
    distandarkan.
\end{enumerate}

\section{Implikasi untuk Penelitian Ini}
\begin{enumerate}[noitemsep]
    \item Merancang pipeline: ekstraksi + segmentasi PDF (layout-aware), indexing
    (sparse/dense), seleksi paragraf, lalu reader IndoBERT-Lite yang di-\textit{fine-
    tune}.
    \item Menyediakan evaluasi EM/F1 dan analisis kesalahan terpisah antara kegagalan
    retrieval dan ekstraksi; menyertakan referensi paragraf/halaman.
    \item Membandingkan skema segmentasi (layout-aware vs paragraf polos) untuk mengukur
    dampaknya pada presisi retrieval dan kualitas jawaban.
\end{enumerate}

\section{Ringkasan Literatur} \label{II.Ringkasan}
\begin{longtable}{|p{0.04\textwidth}|p{0.26\textwidth}|p{0.26\textwidth}|p{0.14\textwidth}|p{0.2\textwidth}|}
    \caption{Ringkasan literatur kunci} \label{table:2.literasi}\\
    \hline
    \textbf{No.} & \textbf{Judul/Referensi} & \textbf{Masalah} & \textbf{Metode} & \textbf{Hasil/Relevansi} \\
    \hline
    \endfirsthead
    \hline
    \textbf{No.} & \textbf{Judul/Referensi} & \textbf{Masalah} & \textbf{Metode} & \textbf{Hasil/Relevansi} \\
    \hline
    \endhead
    1 & PDFTriage \cite{saad2023pdftriage} & QA dokumen PDF panjang/berstruktur & Segmentasi layout + QA & Akurasi meningkat saat struktur halaman dipertahankan \\
    \hline
    2 & SEACrowd \cite{lovenia2024seacrowd} & Kesenjangan data/benchmark SEA & Kumpulan korpus \& tugas multimodal & Legitimasi evaluasi bahasa Indonesia \\
    \hline
    3 & IndoNLU/IndoBERT \cite{wilie2020indonlu,wilie2020indobert} & Kurangnya backbone bahasa Indonesia & Pretrained LM + benchmark & Backbone efisien untuk QA Indonesia \\
    \hline
    4 & DPR \cite{karpukhin2020dpr} & Pemilihan paragraf relevan QA & \textit{Dense passage retrieval} & Baseline retriever untuk pipeline PDF \\
    \hline
    5 & SLP \cite{jurafsky2025slp} & Kerangka teori NLP/IR & Buku teks & Definisi formal, metrik EM/F1 \\
    \hline
\end{longtable}
